{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9da1bca-aca0-4185-924b-1e3e36649ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c18992-38f2-496d-81b3-65e435e75e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nnfs\n",
    "import math\n",
    "\n",
    "from nnfs.datasets import spiral_data\n",
    "from nnfs.datasets import vertical_data\n",
    "\n",
    "from layers import Dense\n",
    "from activations import ReLU\n",
    "from activations import SoftMax\n",
    "from losses import CategoricalCrossEntropy, Softmax_CategoricalCrossentropy\n",
    "from optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85a8fd0-70e7-433b-ae22-10d00bee4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd732f-aa3d-49f0-b155-78663f5965aa",
   "metadata": {},
   "source": [
    "## CH 10: Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d14d110a-bd38-4d0a-b409-d5eaba577b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "X, y = spiral_data(samples=100, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31551c72-b6c7-49b3-8395-99fff3aad329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Layer\n",
    "dense1 = Dense(2, 64)\n",
    "activation1 = ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fab0cb0-6750-4022-b84e-09306fb884f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Layer\n",
    "dense2 = Dense(64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78fb6626-d64b-4471-ba7c-c1bd8549991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical-CrossEntropy with Activation\n",
    "loss_activation = Softmax_CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92fe9e00-7334-4348-bfd4-8cd93da4aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = SGD(learning_rate=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8cc63-2e73-46c9-b9c1-e559a521f52a",
   "metadata": {},
   "source": [
    "### A single Forward-Backward-Optimization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf380cc1-6347-4305-b786-329bcb195d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Pass\n",
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b73bbc72-4367-432f-8e2c-381ccd560ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67091066"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss Computation\n",
    "loss = loss_activation.forward(dense2.output, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9dbaae7b-6b88-444c-ad16-51e2ddade5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_activation.output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ecb1e74-275d-4ebc-8c1d-6990c6af66f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(y.shape) ==2:\n",
    "    y = np.argmax(y, axis=1)\n",
    "    \n",
    "acc = np.mean(predictions==y)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83e60499-6d34-4abd-8c42-7d5db6c201da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Pass\n",
    "loss_activation.backward(loss_activation.output, y)\n",
    "\n",
    "dense2.backward(loss_activation.dinputs)\n",
    "\n",
    "activation1.backward(dense2.dinputs)\n",
    "dense1.backward(activation1.dinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b479f4d0-e6e1-4258-9db1-f8f43b42f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize\n",
    "optimizer.update_params(dense1)\n",
    "optimizer.update_params(dense2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94057a8-76d6-4832-9e8f-064e83b47bf1",
   "metadata": {},
   "source": [
    "### Loop-wise model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95772df5-c51e-4870-a67e-4038047c548d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.343, loss: 1.099\n",
      "epoch: 100, acc: 0.390, loss: 1.089\n",
      "epoch: 200, acc: 0.403, loss: 1.072\n",
      "epoch: 300, acc: 0.400, loss: 1.070\n",
      "epoch: 400, acc: 0.413, loss: 1.069\n",
      "epoch: 500, acc: 0.410, loss: 1.068\n",
      "epoch: 600, acc: 0.413, loss: 1.067\n",
      "epoch: 700, acc: 0.407, loss: 1.065\n",
      "epoch: 800, acc: 0.420, loss: 1.063\n",
      "epoch: 900, acc: 0.433, loss: 1.059\n",
      "epoch: 1000, acc: 0.447, loss: 1.053\n",
      "epoch: 1100, acc: 0.463, loss: 1.042\n",
      "epoch: 1200, acc: 0.510, loss: 1.027\n",
      "epoch: 1300, acc: 0.407, loss: 1.029\n",
      "epoch: 1400, acc: 0.417, loss: 1.021\n",
      "epoch: 1500, acc: 0.423, loss: 1.013\n",
      "epoch: 1600, acc: 0.430, loss: 1.005\n",
      "epoch: 1700, acc: 0.437, loss: 0.996\n",
      "epoch: 1800, acc: 0.437, loss: 1.006\n",
      "epoch: 1900, acc: 0.473, loss: 1.000\n",
      "epoch: 2000, acc: 0.437, loss: 0.977\n",
      "epoch: 2100, acc: 0.473, loss: 0.959\n",
      "epoch: 2200, acc: 0.497, loss: 0.977\n",
      "epoch: 2300, acc: 0.473, loss: 0.954\n",
      "epoch: 2400, acc: 0.473, loss: 0.974\n",
      "epoch: 2500, acc: 0.463, loss: 1.004\n",
      "epoch: 2600, acc: 0.410, loss: 1.035\n",
      "epoch: 2700, acc: 0.537, loss: 0.931\n",
      "epoch: 2800, acc: 0.527, loss: 0.883\n",
      "epoch: 2900, acc: 0.557, loss: 0.876\n",
      "epoch: 3000, acc: 0.557, loss: 0.852\n",
      "epoch: 3100, acc: 0.580, loss: 0.848\n",
      "epoch: 3200, acc: 0.617, loss: 0.813\n",
      "epoch: 3300, acc: 0.613, loss: 0.800\n",
      "epoch: 3400, acc: 0.570, loss: 0.777\n",
      "epoch: 3500, acc: 0.583, loss: 0.737\n",
      "epoch: 3600, acc: 0.597, loss: 0.763\n",
      "epoch: 3700, acc: 0.580, loss: 0.753\n",
      "epoch: 3800, acc: 0.623, loss: 0.707\n",
      "epoch: 3900, acc: 0.613, loss: 0.696\n",
      "epoch: 4000, acc: 0.623, loss: 0.797\n",
      "epoch: 4100, acc: 0.710, loss: 0.644\n",
      "epoch: 4200, acc: 0.680, loss: 0.661\n",
      "epoch: 4300, acc: 0.707, loss: 0.640\n",
      "epoch: 4400, acc: 0.697, loss: 0.640\n",
      "epoch: 4500, acc: 0.687, loss: 0.636\n",
      "epoch: 4600, acc: 0.683, loss: 0.641\n",
      "epoch: 4700, acc: 0.670, loss: 0.677\n",
      "epoch: 4800, acc: 0.643, loss: 0.768\n",
      "epoch: 4900, acc: 0.643, loss: 0.765\n",
      "epoch: 5000, acc: 0.733, loss: 0.562\n",
      "epoch: 5100, acc: 0.750, loss: 0.555\n",
      "epoch: 5200, acc: 0.733, loss: 0.560\n",
      "epoch: 5300, acc: 0.740, loss: 0.563\n",
      "epoch: 5400, acc: 0.750, loss: 0.553\n",
      "epoch: 5500, acc: 0.753, loss: 0.542\n",
      "epoch: 5600, acc: 0.767, loss: 0.540\n",
      "epoch: 5700, acc: 0.770, loss: 0.535\n",
      "epoch: 5800, acc: 0.793, loss: 0.514\n",
      "epoch: 5900, acc: 0.800, loss: 0.505\n",
      "epoch: 6000, acc: 0.787, loss: 0.506\n",
      "epoch: 6100, acc: 0.640, loss: 0.916\n",
      "epoch: 6200, acc: 0.733, loss: 0.564\n",
      "epoch: 6300, acc: 0.770, loss: 0.522\n",
      "epoch: 6400, acc: 0.783, loss: 0.515\n",
      "epoch: 6500, acc: 0.793, loss: 0.512\n",
      "epoch: 6600, acc: 0.797, loss: 0.507\n",
      "epoch: 6700, acc: 0.810, loss: 0.478\n",
      "epoch: 6800, acc: 0.750, loss: 0.564\n",
      "epoch: 6900, acc: 0.793, loss: 0.502\n",
      "epoch: 7000, acc: 0.797, loss: 0.495\n",
      "epoch: 7100, acc: 0.790, loss: 0.524\n",
      "epoch: 7200, acc: 0.790, loss: 0.495\n",
      "epoch: 7300, acc: 0.800, loss: 0.489\n",
      "epoch: 7400, acc: 0.827, loss: 0.461\n",
      "epoch: 7500, acc: 0.787, loss: 0.499\n",
      "epoch: 7600, acc: 0.807, loss: 0.485\n",
      "epoch: 7700, acc: 0.800, loss: 0.492\n",
      "epoch: 7800, acc: 0.810, loss: 0.482\n",
      "epoch: 7900, acc: 0.803, loss: 0.491\n",
      "epoch: 8000, acc: 0.810, loss: 0.481\n",
      "epoch: 8100, acc: 0.813, loss: 0.498\n",
      "epoch: 8200, acc: 0.807, loss: 0.478\n",
      "epoch: 8300, acc: 0.807, loss: 0.472\n",
      "epoch: 8400, acc: 0.807, loss: 0.473\n",
      "epoch: 8500, acc: 0.633, loss: 1.037\n",
      "epoch: 8600, acc: 0.810, loss: 0.473\n",
      "epoch: 8700, acc: 0.807, loss: 0.473\n",
      "epoch: 8800, acc: 0.807, loss: 0.469\n",
      "epoch: 8900, acc: 0.667, loss: 0.949\n",
      "epoch: 9000, acc: 0.810, loss: 0.467\n",
      "epoch: 9100, acc: 0.813, loss: 0.459\n",
      "epoch: 9200, acc: 0.813, loss: 0.465\n",
      "epoch: 9300, acc: 0.820, loss: 0.457\n",
      "epoch: 9400, acc: 0.810, loss: 0.466\n",
      "epoch: 9500, acc: 0.810, loss: 0.464\n",
      "epoch: 9600, acc: 0.817, loss: 0.461\n",
      "epoch: 9700, acc: 0.803, loss: 0.469\n",
      "epoch: 9800, acc: 0.817, loss: 0.460\n",
      "epoch: 9900, acc: 0.800, loss: 0.524\n",
      "epoch: 10000, acc: 0.813, loss: 0.454\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10001):\n",
    "    # Forward Pass\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    dense2.forward(activation1.output)\n",
    "    # Loss Computation\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    # Accuracy\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) ==2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "\n",
    "    acc = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {acc:.3f}, ' +\n",
    "              f'loss: {loss:.3f}')\n",
    "\n",
    "    # Backward Pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    # Optimize\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86090225-a7c7-4463-809e-c90ec508afc5",
   "metadata": {},
   "source": [
    "### Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dbe4a97-d0ca-4a11-9a17-7a33d751bd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_learning_rate = 1.\n",
    "learning_rate_decay = 0.1\n",
    "step = 1\n",
    "\n",
    "learning_rate = starting_learning_rate * (1. / (1 + learning_rate_decay * step))\n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4c1ca28-53b0-4e96-9714-c59e1d5a6b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_learning_rate = 1.\n",
    "learning_rate_decay = 0.1\n",
    "step = 20\n",
    "\n",
    "learning_rate = starting_learning_rate * (1. / (1 + learning_rate_decay * step))\n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8117c20c-dcd6-45eb-beca-a7075513c658",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  1.0\n",
      "LR:  0.9090909090909091\n",
      "LR:  0.8333333333333334\n",
      "LR:  0.7692307692307692\n",
      "LR:  0.7142857142857143\n",
      "LR:  0.6666666666666666\n",
      "LR:  0.625\n",
      "LR:  0.588235294117647\n",
      "LR:  0.5555555555555556\n",
      "LR:  0.5263157894736842\n",
      "LR:  0.5\n",
      "LR:  0.47619047619047616\n",
      "LR:  0.45454545454545453\n",
      "LR:  0.4347826086956522\n",
      "LR:  0.41666666666666663\n",
      "LR:  0.4\n",
      "LR:  0.3846153846153846\n",
      "LR:  0.37037037037037035\n",
      "LR:  0.35714285714285715\n",
      "LR:  0.3448275862068965\n"
     ]
    }
   ],
   "source": [
    "starting_learning_rate = 1.\n",
    "learning_rate_decay = 0.1\n",
    "\n",
    "for step in range(20):\n",
    "    learning_rate = starting_learning_rate * (1. / (1 + learning_rate_decay * step))\n",
    "    print(\"LR: \",learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d023568c-44e6-4696-80a5-a8747b95ca76",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.317, loss: 1.099, lr: 1.0\n",
      "epoch: 100, acc: 0.403, loss: 1.092, lr: 0.9099181073703367\n",
      "epoch: 200, acc: 0.423, loss: 1.080, lr: 0.8340283569641367\n",
      "epoch: 300, acc: 0.420, loss: 1.077, lr: 0.7698229407236336\n",
      "epoch: 400, acc: 0.430, loss: 1.076, lr: 0.7147962830593281\n",
      "epoch: 500, acc: 0.413, loss: 1.073, lr: 0.66711140760507\n",
      "epoch: 600, acc: 0.413, loss: 1.069, lr: 0.6253908692933083\n",
      "epoch: 700, acc: 0.403, loss: 1.063, lr: 0.5885815185403178\n",
      "epoch: 800, acc: 0.393, loss: 1.056, lr: 0.5558643690939411\n",
      "epoch: 900, acc: 0.450, loss: 1.049, lr: 0.526592943654555\n",
      "epoch: 1000, acc: 0.467, loss: 1.042, lr: 0.5002501250625312\n",
      "epoch: 1100, acc: 0.443, loss: 1.037, lr: 0.4764173415912339\n",
      "epoch: 1200, acc: 0.433, loss: 1.031, lr: 0.45475216007276037\n",
      "epoch: 1300, acc: 0.430, loss: 1.027, lr: 0.43497172683775553\n",
      "epoch: 1400, acc: 0.427, loss: 1.022, lr: 0.4168403501458941\n",
      "epoch: 1500, acc: 0.430, loss: 1.016, lr: 0.4001600640256102\n",
      "epoch: 1600, acc: 0.433, loss: 1.009, lr: 0.3847633705271258\n",
      "epoch: 1700, acc: 0.437, loss: 1.001, lr: 0.3705075954057058\n",
      "epoch: 1800, acc: 0.450, loss: 0.994, lr: 0.35727045373347627\n",
      "epoch: 1900, acc: 0.467, loss: 0.984, lr: 0.3449465332873405\n",
      "epoch: 2000, acc: 0.493, loss: 0.974, lr: 0.33344448149383127\n",
      "epoch: 2100, acc: 0.493, loss: 0.965, lr: 0.32268473701193934\n",
      "epoch: 2200, acc: 0.497, loss: 0.957, lr: 0.31259768677711786\n",
      "epoch: 2300, acc: 0.510, loss: 0.950, lr: 0.3031221582297666\n",
      "epoch: 2400, acc: 0.510, loss: 0.943, lr: 0.29420417769932333\n",
      "epoch: 2500, acc: 0.517, loss: 0.936, lr: 0.2857959416976279\n",
      "epoch: 2600, acc: 0.530, loss: 0.930, lr: 0.2778549597110308\n",
      "epoch: 2700, acc: 0.540, loss: 0.924, lr: 0.2703433360367667\n",
      "epoch: 2800, acc: 0.540, loss: 0.918, lr: 0.26322716504343247\n",
      "epoch: 2900, acc: 0.547, loss: 0.912, lr: 0.25647601949217746\n",
      "epoch: 3000, acc: 0.553, loss: 0.906, lr: 0.25006251562890724\n",
      "epoch: 3100, acc: 0.557, loss: 0.901, lr: 0.2439619419370578\n",
      "epoch: 3200, acc: 0.560, loss: 0.897, lr: 0.23815194093831865\n",
      "epoch: 3300, acc: 0.543, loss: 0.896, lr: 0.23261223540358225\n",
      "epoch: 3400, acc: 0.540, loss: 0.895, lr: 0.22732439190725165\n",
      "epoch: 3500, acc: 0.543, loss: 0.897, lr: 0.22227161591464767\n",
      "epoch: 3600, acc: 0.547, loss: 0.895, lr: 0.21743857360295715\n",
      "epoch: 3700, acc: 0.543, loss: 0.891, lr: 0.21281123643328367\n",
      "epoch: 3800, acc: 0.550, loss: 0.886, lr: 0.20837674515524068\n",
      "epoch: 3900, acc: 0.553, loss: 0.884, lr: 0.20412329046744235\n",
      "epoch: 4000, acc: 0.553, loss: 0.881, lr: 0.2000400080016003\n",
      "epoch: 4100, acc: 0.547, loss: 0.878, lr: 0.19611688566385566\n",
      "epoch: 4200, acc: 0.550, loss: 0.875, lr: 0.19234468166955185\n",
      "epoch: 4300, acc: 0.553, loss: 0.871, lr: 0.18871485185884126\n",
      "epoch: 4400, acc: 0.553, loss: 0.868, lr: 0.18521948508983144\n",
      "epoch: 4500, acc: 0.553, loss: 0.865, lr: 0.18185124568103292\n",
      "epoch: 4600, acc: 0.560, loss: 0.861, lr: 0.1786033220217896\n",
      "epoch: 4700, acc: 0.567, loss: 0.857, lr: 0.1754693805930865\n",
      "epoch: 4800, acc: 0.567, loss: 0.852, lr: 0.17244352474564578\n",
      "epoch: 4900, acc: 0.563, loss: 0.850, lr: 0.16952025767079165\n",
      "epoch: 5000, acc: 0.570, loss: 0.845, lr: 0.16669444907484582\n",
      "epoch: 5100, acc: 0.567, loss: 0.845, lr: 0.16396130513198884\n",
      "epoch: 5200, acc: 0.567, loss: 0.841, lr: 0.16131634134537828\n",
      "epoch: 5300, acc: 0.567, loss: 0.835, lr: 0.15875535799333226\n",
      "epoch: 5400, acc: 0.563, loss: 0.830, lr: 0.1562744178777934\n",
      "epoch: 5500, acc: 0.563, loss: 0.827, lr: 0.15386982612709646\n",
      "epoch: 5600, acc: 0.563, loss: 0.824, lr: 0.15153811183512653\n",
      "epoch: 5700, acc: 0.567, loss: 0.820, lr: 0.14927601134497687\n",
      "epoch: 5800, acc: 0.573, loss: 0.815, lr: 0.14708045300779526\n",
      "epoch: 5900, acc: 0.580, loss: 0.809, lr: 0.14494854326714016\n",
      "epoch: 6000, acc: 0.580, loss: 0.804, lr: 0.1428775539362766\n",
      "epoch: 6100, acc: 0.587, loss: 0.799, lr: 0.1408649105507818\n",
      "epoch: 6200, acc: 0.590, loss: 0.794, lr: 0.13890818169190167\n",
      "epoch: 6300, acc: 0.593, loss: 0.788, lr: 0.13700506918755992\n",
      "epoch: 6400, acc: 0.593, loss: 0.784, lr: 0.13515339910798757\n",
      "epoch: 6500, acc: 0.593, loss: 0.780, lr: 0.13335111348179757\n",
      "epoch: 6600, acc: 0.597, loss: 0.776, lr: 0.13159626266614027\n",
      "epoch: 6700, acc: 0.600, loss: 0.771, lr: 0.12988699831146902\n",
      "epoch: 6800, acc: 0.603, loss: 0.767, lr: 0.12822156686754713\n",
      "epoch: 6900, acc: 0.610, loss: 0.762, lr: 0.126598303582732\n",
      "epoch: 7000, acc: 0.610, loss: 0.758, lr: 0.12501562695336915\n",
      "epoch: 7100, acc: 0.617, loss: 0.754, lr: 0.12347203358439313\n",
      "epoch: 7200, acc: 0.620, loss: 0.749, lr: 0.12196609342602757\n",
      "epoch: 7300, acc: 0.627, loss: 0.744, lr: 0.12049644535486204\n",
      "epoch: 7400, acc: 0.630, loss: 0.740, lr: 0.11906179307060363\n",
      "epoch: 7500, acc: 0.630, loss: 0.736, lr: 0.11766090128250381\n",
      "epoch: 7600, acc: 0.637, loss: 0.730, lr: 0.11629259216187929\n",
      "epoch: 7700, acc: 0.640, loss: 0.726, lr: 0.11495574203931487\n",
      "epoch: 7800, acc: 0.640, loss: 0.721, lr: 0.11364927832708263\n",
      "epoch: 7900, acc: 0.647, loss: 0.716, lr: 0.11237217664906168\n",
      "epoch: 8000, acc: 0.653, loss: 0.712, lr: 0.11112345816201799\n",
      "epoch: 8100, acc: 0.657, loss: 0.707, lr: 0.10990218705352237\n",
      "epoch: 8200, acc: 0.663, loss: 0.703, lr: 0.10870746820306555\n",
      "epoch: 8300, acc: 0.663, loss: 0.699, lr: 0.1075384449940854\n",
      "epoch: 8400, acc: 0.663, loss: 0.694, lr: 0.10639429726566654\n",
      "epoch: 8500, acc: 0.667, loss: 0.690, lr: 0.10527423939362038\n",
      "epoch: 8600, acc: 0.667, loss: 0.686, lr: 0.10417751849150952\n",
      "epoch: 8700, acc: 0.670, loss: 0.682, lr: 0.10310341272296113\n",
      "epoch: 8800, acc: 0.670, loss: 0.677, lr: 0.1020512297173181\n",
      "epoch: 8900, acc: 0.673, loss: 0.673, lr: 0.10102030508132134\n",
      "epoch: 9000, acc: 0.673, loss: 0.670, lr: 0.1000100010001\n",
      "epoch: 9100, acc: 0.673, loss: 0.666, lr: 0.09901970492127933\n",
      "epoch: 9200, acc: 0.677, loss: 0.663, lr: 0.09804882831650162\n",
      "epoch: 9300, acc: 0.677, loss: 0.659, lr: 0.09709680551509856\n",
      "epoch: 9400, acc: 0.680, loss: 0.655, lr: 0.09616309260505818\n",
      "epoch: 9500, acc: 0.683, loss: 0.651, lr: 0.09524716639679968\n",
      "epoch: 9600, acc: 0.687, loss: 0.648, lr: 0.09434852344560807\n",
      "epoch: 9700, acc: 0.693, loss: 0.645, lr: 0.09346667912889055\n",
      "epoch: 9800, acc: 0.697, loss: 0.642, lr: 0.09260116677470137\n",
      "epoch: 9900, acc: 0.697, loss: 0.639, lr: 0.09175153683824203\n",
      "epoch: 10000, acc: 0.697, loss: 0.637, lr: 0.09091735612328393\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# First Layer\n",
    "dense1 = Dense(2, 64)\n",
    "activation1 = ReLU()\n",
    "\n",
    "# Second Layer\n",
    "dense2 = Dense(64, 3)\n",
    "\n",
    "# Categorical-CrossEntropy with Activation\n",
    "loss_activation = Softmax_CategoricalCrossentropy()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = SGD(decay=1e-3)\n",
    "\n",
    "for epoch in range(10001):\n",
    "    # Forward Pass\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    dense2.forward(activation1.output)\n",
    "    # Loss Computation\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    # Accuracy\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) ==2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "\n",
    "    acc = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {acc:.3f}, ' +\n",
    "              f'loss: {loss:.3f}, ' +\n",
    "              f'lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "    # Backward Pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    # Optimize\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669cef1-1ab3-498d-8dec-e007cfe644c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
