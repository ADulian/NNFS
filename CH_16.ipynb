{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9da1bca-aca0-4185-924b-1e3e36649ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c18992-38f2-496d-81b3-65e435e75e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nnfs\n",
    "import math\n",
    "import random\n",
    "\n",
    "from nnfs.datasets import spiral_data\n",
    "from nnfs.datasets import vertical_data\n",
    "\n",
    "from layers import Dense, Dropout\n",
    "from activations import ReLU\n",
    "from activations import SoftMax\n",
    "from losses import CategoricalCrossEntropy, Softmax_CategoricalCrossentropy\n",
    "from optimizers import SGD, AdaGrad, RMSProp, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85a8fd0-70e7-433b-ae22-10d00bee4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd732f-aa3d-49f0-b155-78663f5965aa",
   "metadata": {},
   "source": [
    "## CH 16: Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a913c7f4-d4b6-44ad-ab1f-e2b28fe7fb51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.370, loss: 1.099, data_loss: 1.099 reg_loss: 0.000 lr: 0.05 \n",
      "epoch: 1000, acc: 0.693, loss: 0.767, data_loss: 0.722 reg_loss: 0.045 lr: 0.04762131530072861 \n",
      "epoch: 2000, acc: 0.647, loss: 0.771, data_loss: 0.727 reg_loss: 0.044 lr: 0.045456611664166556 \n",
      "epoch: 3000, acc: 0.710, loss: 0.658, data_loss: 0.612 reg_loss: 0.046 lr: 0.043480151310926564 \n",
      "epoch: 4000, acc: 0.700, loss: 0.696, data_loss: 0.649 reg_loss: 0.047 lr: 0.04166840285011875 \n",
      "epoch: 5000, acc: 0.747, loss: 0.640, data_loss: 0.593 reg_loss: 0.048 lr: 0.04000160006400256 \n",
      "epoch: 6000, acc: 0.730, loss: 0.649, data_loss: 0.602 reg_loss: 0.047 lr: 0.03846301780837725 \n",
      "epoch: 7000, acc: 0.720, loss: 0.661, data_loss: 0.614 reg_loss: 0.046 lr: 0.03703840882995667 \n",
      "epoch: 8000, acc: 0.723, loss: 0.662, data_loss: 0.616 reg_loss: 0.046 lr: 0.03571556127004536 \n",
      "epoch: 9000, acc: 0.723, loss: 0.737, data_loss: 0.691 reg_loss: 0.047 lr: 0.034483947722335255 \n",
      "epoch: 10000, acc: 0.723, loss: 0.668, data_loss: 0.622 reg_loss: 0.046 lr: 0.03333444448148271 \n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# First Layer\n",
    "dense1 = Dense(2, 64, weight_regularizer_l2=5e-4, bias_regularizer_l2=5e-4)\n",
    "activation1 = ReLU()\n",
    "dropout1 = Dropout(0.1)\n",
    "\n",
    "# Second Layer\n",
    "dense2 = Dense(64, 3)\n",
    "\n",
    "# Categorical-CrossEntropy with Activation\n",
    "loss_activation = Softmax_CategoricalCrossentropy()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(decay=5e-5, learning_rate=0.05)\n",
    "\n",
    "for epoch in range(10001):\n",
    "    # Forward Pass\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dropout1.forward(activation1.output)\n",
    "\n",
    "    dense2.forward(dropout1.output)\n",
    "    \n",
    "    # Loss Computation\n",
    "    # Data\n",
    "    data_loss = loss_activation.forward(dense2.output, y)\n",
    "    \n",
    "    # Regularization termr\n",
    "    regularization_loss = loss_activation.regularization_loss(dense1) + loss_activation.regularization_loss(dense2)\n",
    "    \n",
    "    # Total\n",
    "    loss = data_loss + regularization_loss\n",
    "    \n",
    "    # Accuracy\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) ==2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "\n",
    "    acc = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 1000:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {acc:.3f}, ' +\n",
    "              f'loss: {loss:.3f}, ' +\n",
    "              f'data_loss: {data_loss:.3f} ' +\n",
    "              f'reg_loss: {regularization_loss:.3f} ' +\n",
    "              f'lr: {optimizer.current_learning_rate} ')\n",
    "\n",
    "    # Backward Pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    \n",
    "    dropout1.backward(dense2.dinputs)\n",
    "    activation1.backward(dropout1.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    # Optimize\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f669cef1-1ab3-498d-8dec-e007cfe644c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.717, loss: 0.691\n"
     ]
    }
   ],
   "source": [
    "# Create test set\n",
    "X_test, y_test = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "# Forward pass\n",
    "\n",
    "dense1.forward(X_test)\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "loss = loss_activation.forward(dense2.output, y_test)\n",
    "\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(y.shape) ==2:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "acc = np.mean(predictions==y_test)\n",
    "\n",
    "print(f'Validation acc: {acc:.3f}, loss: {loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68beff67-7423-4d61-8ab4-f242cde38166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
