{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9da1bca-aca0-4185-924b-1e3e36649ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c18992-38f2-496d-81b3-65e435e75e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nnfs\n",
    "import math\n",
    "\n",
    "from nnfs.datasets import spiral_data\n",
    "from nnfs.datasets import vertical_data\n",
    "\n",
    "from layers import Dense\n",
    "from activations import ReLU\n",
    "from activations import SoftMax\n",
    "from losses import CategoricalCrossEntropy, Softmax_CategoricalCrossentropy\n",
    "from optimizers import SGD, AdaGrad, RMSProp, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85a8fd0-70e7-433b-ae22-10d00bee4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd732f-aa3d-49f0-b155-78663f5965aa",
   "metadata": {},
   "source": [
    "## CH 14: L1 and L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a913c7f4-d4b6-44ad-ab1f-e2b28fe7fb51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.327, loss: 1.099, data_loss: 1.099 reg_loss: 0.000 lr: 0.05 \n",
      "epoch: 100, acc: 0.763, loss: 0.667, data_loss: 0.601 reg_loss: 0.066 lr: 0.04999752512250644 \n",
      "epoch: 200, acc: 0.857, loss: 0.510, data_loss: 0.414 reg_loss: 0.096 lr: 0.04999502549496326 \n",
      "epoch: 300, acc: 0.883, loss: 0.486, data_loss: 0.367 reg_loss: 0.119 lr: 0.049992526117345455 \n",
      "epoch: 400, acc: 0.907, loss: 0.401, data_loss: 0.289 reg_loss: 0.112 lr: 0.04999002698961558 \n",
      "epoch: 500, acc: 0.920, loss: 0.361, data_loss: 0.250 reg_loss: 0.111 lr: 0.049987528111736124 \n",
      "epoch: 600, acc: 0.927, loss: 0.338, data_loss: 0.232 reg_loss: 0.106 lr: 0.049985029483669646 \n",
      "epoch: 700, acc: 0.930, loss: 0.323, data_loss: 0.222 reg_loss: 0.101 lr: 0.049982531105378675 \n",
      "epoch: 800, acc: 0.930, loss: 0.328, data_loss: 0.216 reg_loss: 0.112 lr: 0.04998003297682575 \n",
      "epoch: 900, acc: 0.937, loss: 0.307, data_loss: 0.205 reg_loss: 0.101 lr: 0.049977535097973466 \n",
      "epoch: 1000, acc: 0.930, loss: 0.295, data_loss: 0.200 reg_loss: 0.095 lr: 0.049975037468784345 \n",
      "epoch: 1100, acc: 0.750, loss: 1.118, data_loss: 1.027 reg_loss: 0.091 lr: 0.049972540089220974 \n",
      "epoch: 1200, acc: 0.940, loss: 0.315, data_loss: 0.204 reg_loss: 0.112 lr: 0.04997004295924593 \n",
      "epoch: 1300, acc: 0.940, loss: 0.297, data_loss: 0.193 reg_loss: 0.104 lr: 0.04996754607882181 \n",
      "epoch: 1400, acc: 0.933, loss: 0.291, data_loss: 0.193 reg_loss: 0.098 lr: 0.049965049447911185 \n",
      "epoch: 1500, acc: 0.943, loss: 0.274, data_loss: 0.181 reg_loss: 0.093 lr: 0.04996255306647668 \n",
      "epoch: 1600, acc: 0.943, loss: 0.264, data_loss: 0.176 reg_loss: 0.089 lr: 0.049960056934480884 \n",
      "epoch: 1700, acc: 0.913, loss: 0.386, data_loss: 0.246 reg_loss: 0.140 lr: 0.04995756105188642 \n",
      "epoch: 1800, acc: 0.943, loss: 0.296, data_loss: 0.186 reg_loss: 0.110 lr: 0.049955065418655915 \n",
      "epoch: 1900, acc: 0.943, loss: 0.282, data_loss: 0.180 reg_loss: 0.102 lr: 0.04995257003475201 \n",
      "epoch: 2000, acc: 0.947, loss: 0.271, data_loss: 0.175 reg_loss: 0.096 lr: 0.04995007490013731 \n",
      "epoch: 2100, acc: 0.943, loss: 0.263, data_loss: 0.172 reg_loss: 0.091 lr: 0.0499475800147745 \n",
      "epoch: 2200, acc: 0.953, loss: 0.260, data_loss: 0.168 reg_loss: 0.092 lr: 0.0499450853786262 \n",
      "epoch: 2300, acc: 0.953, loss: 0.249, data_loss: 0.164 reg_loss: 0.085 lr: 0.0499425909916551 \n",
      "epoch: 2400, acc: 0.927, loss: 0.266, data_loss: 0.183 reg_loss: 0.082 lr: 0.04994009685382384 \n",
      "epoch: 2500, acc: 0.953, loss: 0.239, data_loss: 0.161 reg_loss: 0.078 lr: 0.04993760296509512 \n",
      "epoch: 2600, acc: 0.957, loss: 0.235, data_loss: 0.160 reg_loss: 0.075 lr: 0.049935109325431604 \n",
      "epoch: 2700, acc: 0.927, loss: 0.329, data_loss: 0.215 reg_loss: 0.115 lr: 0.049932615934796004 \n",
      "epoch: 2800, acc: 0.933, loss: 0.297, data_loss: 0.194 reg_loss: 0.104 lr: 0.04993012279315098 \n",
      "epoch: 2900, acc: 0.933, loss: 0.287, data_loss: 0.186 reg_loss: 0.101 lr: 0.049927629900459285 \n",
      "epoch: 3000, acc: 0.937, loss: 0.271, data_loss: 0.177 reg_loss: 0.094 lr: 0.049925137256683606 \n",
      "epoch: 3100, acc: 0.933, loss: 0.275, data_loss: 0.180 reg_loss: 0.095 lr: 0.04992264486178666 \n",
      "epoch: 3200, acc: 0.943, loss: 0.258, data_loss: 0.171 reg_loss: 0.087 lr: 0.04992015271573119 \n",
      "epoch: 3300, acc: 0.950, loss: 0.252, data_loss: 0.169 reg_loss: 0.083 lr: 0.04991766081847992 \n",
      "epoch: 3400, acc: 0.950, loss: 0.250, data_loss: 0.170 reg_loss: 0.080 lr: 0.049915169169995596 \n",
      "epoch: 3500, acc: 0.933, loss: 0.252, data_loss: 0.174 reg_loss: 0.077 lr: 0.049912677770240964 \n",
      "epoch: 3600, acc: 0.647, loss: 1.818, data_loss: 1.725 reg_loss: 0.093 lr: 0.049910186619178794 \n",
      "epoch: 3700, acc: 0.953, loss: 0.267, data_loss: 0.171 reg_loss: 0.097 lr: 0.04990769571677183 \n",
      "epoch: 3800, acc: 0.950, loss: 0.257, data_loss: 0.166 reg_loss: 0.092 lr: 0.04990520506298287 \n",
      "epoch: 3900, acc: 0.957, loss: 0.247, data_loss: 0.160 reg_loss: 0.086 lr: 0.04990271465777467 \n",
      "epoch: 4000, acc: 0.950, loss: 0.245, data_loss: 0.162 reg_loss: 0.083 lr: 0.049900224501110035 \n",
      "epoch: 4100, acc: 0.950, loss: 0.235, data_loss: 0.156 reg_loss: 0.080 lr: 0.04989773459295174 \n",
      "epoch: 4200, acc: 0.943, loss: 0.236, data_loss: 0.159 reg_loss: 0.077 lr: 0.04989524493326262 \n",
      "epoch: 4300, acc: 0.947, loss: 0.228, data_loss: 0.151 reg_loss: 0.076 lr: 0.04989275552200545 \n",
      "epoch: 4400, acc: 0.953, loss: 0.224, data_loss: 0.150 reg_loss: 0.073 lr: 0.04989026635914307 \n",
      "epoch: 4500, acc: 0.933, loss: 0.279, data_loss: 0.206 reg_loss: 0.073 lr: 0.04988777744463829 \n",
      "epoch: 4600, acc: 0.947, loss: 0.225, data_loss: 0.147 reg_loss: 0.078 lr: 0.049885288778453954 \n",
      "epoch: 4700, acc: 0.947, loss: 0.219, data_loss: 0.146 reg_loss: 0.073 lr: 0.049882800360552884 \n",
      "epoch: 4800, acc: 0.953, loss: 0.215, data_loss: 0.145 reg_loss: 0.070 lr: 0.04988031219089794 \n",
      "epoch: 4900, acc: 0.947, loss: 0.213, data_loss: 0.145 reg_loss: 0.068 lr: 0.049877824269451976 \n",
      "epoch: 5000, acc: 0.947, loss: 0.211, data_loss: 0.144 reg_loss: 0.066 lr: 0.04987533659617785 \n",
      "epoch: 5100, acc: 0.947, loss: 0.304, data_loss: 0.187 reg_loss: 0.116 lr: 0.04987284917103844 \n",
      "epoch: 5200, acc: 0.943, loss: 0.242, data_loss: 0.156 reg_loss: 0.085 lr: 0.04987036199399661 \n",
      "epoch: 5300, acc: 0.947, loss: 0.238, data_loss: 0.155 reg_loss: 0.084 lr: 0.04986787506501525 \n",
      "epoch: 5400, acc: 0.943, loss: 0.230, data_loss: 0.152 reg_loss: 0.078 lr: 0.04986538838405724 \n",
      "epoch: 5500, acc: 0.947, loss: 0.228, data_loss: 0.151 reg_loss: 0.077 lr: 0.049862901951085496 \n",
      "epoch: 5600, acc: 0.943, loss: 0.222, data_loss: 0.149 reg_loss: 0.073 lr: 0.049860415766062906 \n",
      "epoch: 5700, acc: 0.957, loss: 0.220, data_loss: 0.149 reg_loss: 0.071 lr: 0.0498579298289524 \n",
      "epoch: 5800, acc: 0.950, loss: 0.218, data_loss: 0.147 reg_loss: 0.071 lr: 0.04985544413971689 \n",
      "epoch: 5900, acc: 0.947, loss: 0.212, data_loss: 0.143 reg_loss: 0.068 lr: 0.049852958698319315 \n",
      "epoch: 6000, acc: 0.953, loss: 0.209, data_loss: 0.143 reg_loss: 0.067 lr: 0.04985047350472258 \n",
      "epoch: 6100, acc: 0.953, loss: 0.209, data_loss: 0.143 reg_loss: 0.066 lr: 0.04984798855888967 \n",
      "epoch: 6200, acc: 0.873, loss: 0.482, data_loss: 0.394 reg_loss: 0.088 lr: 0.049845503860783506 \n",
      "epoch: 6300, acc: 0.943, loss: 0.223, data_loss: 0.148 reg_loss: 0.075 lr: 0.049843019410367055 \n",
      "epoch: 6400, acc: 0.947, loss: 0.216, data_loss: 0.145 reg_loss: 0.071 lr: 0.04984053520760327 \n",
      "epoch: 6500, acc: 0.947, loss: 0.213, data_loss: 0.144 reg_loss: 0.069 lr: 0.049838051252455155 \n",
      "epoch: 6600, acc: 0.943, loss: 0.209, data_loss: 0.143 reg_loss: 0.066 lr: 0.049835567544885655 \n",
      "epoch: 6700, acc: 0.817, loss: 0.609, data_loss: 0.510 reg_loss: 0.099 lr: 0.04983308408485778 \n",
      "epoch: 6800, acc: 0.940, loss: 0.227, data_loss: 0.149 reg_loss: 0.078 lr: 0.0498306008723345 \n",
      "epoch: 6900, acc: 0.937, loss: 0.229, data_loss: 0.156 reg_loss: 0.073 lr: 0.04982811790727884 \n",
      "epoch: 7000, acc: 0.943, loss: 0.213, data_loss: 0.143 reg_loss: 0.070 lr: 0.04982563518965381 \n",
      "epoch: 7100, acc: 0.943, loss: 0.220, data_loss: 0.152 reg_loss: 0.068 lr: 0.049823152719422406 \n",
      "epoch: 7200, acc: 0.907, loss: 0.282, data_loss: 0.215 reg_loss: 0.067 lr: 0.049820670496547675 \n",
      "epoch: 7300, acc: 0.947, loss: 0.206, data_loss: 0.140 reg_loss: 0.066 lr: 0.04981818852099264 \n",
      "epoch: 7400, acc: 0.950, loss: 0.202, data_loss: 0.138 reg_loss: 0.063 lr: 0.049815706792720335 \n",
      "epoch: 7500, acc: 0.910, loss: 0.256, data_loss: 0.189 reg_loss: 0.067 lr: 0.0498132253116938 \n",
      "epoch: 7600, acc: 0.950, loss: 0.227, data_loss: 0.146 reg_loss: 0.080 lr: 0.04981074407787611 \n",
      "epoch: 7700, acc: 0.957, loss: 0.210, data_loss: 0.138 reg_loss: 0.071 lr: 0.049808263091230306 \n",
      "epoch: 7800, acc: 0.950, loss: 0.207, data_loss: 0.138 reg_loss: 0.070 lr: 0.04980578235171948 \n",
      "epoch: 7900, acc: 0.953, loss: 0.203, data_loss: 0.137 reg_loss: 0.066 lr: 0.04980330185930667 \n",
      "epoch: 8000, acc: 0.953, loss: 0.207, data_loss: 0.142 reg_loss: 0.066 lr: 0.04980082161395499 \n",
      "epoch: 8100, acc: 0.950, loss: 0.221, data_loss: 0.136 reg_loss: 0.085 lr: 0.04979834161562752 \n",
      "epoch: 8200, acc: 0.953, loss: 0.205, data_loss: 0.131 reg_loss: 0.074 lr: 0.04979586186428736 \n",
      "epoch: 8300, acc: 0.960, loss: 0.200, data_loss: 0.131 reg_loss: 0.070 lr: 0.04979338235989761 \n",
      "epoch: 8400, acc: 0.947, loss: 0.199, data_loss: 0.131 reg_loss: 0.068 lr: 0.04979090310242139 \n",
      "epoch: 8500, acc: 0.950, loss: 0.219, data_loss: 0.136 reg_loss: 0.082 lr: 0.049788424091821805 \n",
      "epoch: 8600, acc: 0.950, loss: 0.205, data_loss: 0.133 reg_loss: 0.072 lr: 0.049785945328062006 \n",
      "epoch: 8700, acc: 0.917, loss: 0.335, data_loss: 0.236 reg_loss: 0.098 lr: 0.0497834668111051 \n",
      "epoch: 8800, acc: 0.947, loss: 0.213, data_loss: 0.134 reg_loss: 0.079 lr: 0.049780988540914256 \n",
      "epoch: 8900, acc: 0.950, loss: 0.203, data_loss: 0.132 reg_loss: 0.071 lr: 0.0497785105174526 \n",
      "epoch: 9000, acc: 0.953, loss: 0.198, data_loss: 0.131 reg_loss: 0.067 lr: 0.04977603274068329 \n",
      "epoch: 9100, acc: 0.957, loss: 0.193, data_loss: 0.128 reg_loss: 0.065 lr: 0.04977355521056952 \n",
      "epoch: 9200, acc: 0.957, loss: 0.198, data_loss: 0.133 reg_loss: 0.064 lr: 0.049771077927074414 \n",
      "epoch: 9300, acc: 0.950, loss: 0.193, data_loss: 0.132 reg_loss: 0.061 lr: 0.0497686008901612 \n",
      "epoch: 9400, acc: 0.943, loss: 0.192, data_loss: 0.133 reg_loss: 0.059 lr: 0.04976612409979302 \n",
      "epoch: 9500, acc: 0.950, loss: 0.193, data_loss: 0.134 reg_loss: 0.059 lr: 0.0497636475559331 \n",
      "epoch: 9600, acc: 0.950, loss: 0.188, data_loss: 0.132 reg_loss: 0.057 lr: 0.049761171258544616 \n",
      "epoch: 9700, acc: 0.890, loss: 0.343, data_loss: 0.283 reg_loss: 0.060 lr: 0.0497586952075908 \n",
      "epoch: 9800, acc: 0.943, loss: 0.220, data_loss: 0.145 reg_loss: 0.076 lr: 0.04975621940303483 \n",
      "epoch: 9900, acc: 0.960, loss: 0.207, data_loss: 0.139 reg_loss: 0.068 lr: 0.049753743844839965 \n",
      "epoch: 10000, acc: 0.910, loss: 0.280, data_loss: 0.213 reg_loss: 0.067 lr: 0.04975126853296942 \n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# First Layer\n",
    "dense1 = Dense(2, 512, weight_regularizer_l2=5e-4, bias_regularizer_l2=5e-4)\n",
    "activation1 = ReLU()\n",
    "\n",
    "# Second Layer\n",
    "dense2 = Dense(512, 3)\n",
    "\n",
    "# Categorical-CrossEntropy with Activation\n",
    "loss_activation = Softmax_CategoricalCrossentropy()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(decay=5e-7, learning_rate=0.05)\n",
    "\n",
    "for epoch in range(10001):\n",
    "    # Forward Pass\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    dense2.forward(activation1.output)\n",
    "    \n",
    "    # Loss Computation\n",
    "    # Data\n",
    "    data_loss = loss_activation.forward(dense2.output, y)\n",
    "    \n",
    "    # Regularization termr\n",
    "    regularization_loss = loss_activation.regularization_loss(dense1) + loss_activation.regularization_loss(dense2)\n",
    "    \n",
    "    # Total\n",
    "    loss = data_loss + regularization_loss\n",
    "    \n",
    "    # Accuracy\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) ==2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "\n",
    "    acc = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {acc:.3f}, ' +\n",
    "              f'loss: {loss:.3f}, ' +\n",
    "              f'data_loss: {data_loss:.3f} ' +\n",
    "              f'reg_loss: {regularization_loss:.3f} ' +\n",
    "              f'lr: {optimizer.current_learning_rate} ')\n",
    "\n",
    "    # Backward Pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    # Optimize\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f669cef1-1ab3-498d-8dec-e007cfe644c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.817, loss: 0.722\n"
     ]
    }
   ],
   "source": [
    "# Create test set\n",
    "X_test, y_test = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "# Forward pass\n",
    "\n",
    "dense1.forward(X_test)\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "loss = loss_activation.forward(dense2.output, y_test)\n",
    "\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(y.shape) ==2:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "acc = np.mean(predictions==y_test)\n",
    "\n",
    "print(f'Validation acc: {acc:.3f}, loss: {loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f5f4f5-0055-4ae9-a0de-56119e47d79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.900, loss: 0.292\n"
     ]
    }
   ],
   "source": [
    "# Create test set\n",
    "X_test, y_test = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "# Forward pass\n",
    "\n",
    "dense1.forward(X_test)\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "loss = loss_activation.forward(dense2.output, y_test)\n",
    "\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(y.shape) ==2:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "acc = np.mean(predictions==y_test)\n",
    "\n",
    "print(f'Validation acc: {acc:.3f}, loss: {loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c41269c-22ad-4ef7-951d-484d6d67f88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.820, loss: 0.723\n"
     ]
    }
   ],
   "source": [
    "# Create test set\n",
    "X_test, y_test = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "# Forward pass\n",
    "\n",
    "dense1.forward(X_test)\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "loss = loss_activation.forward(dense2.output, y_test)\n",
    "\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(y.shape) ==2:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "acc = np.mean(predictions==y_test)\n",
    "\n",
    "print(f'Validation acc: {acc:.3f}, loss: {loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68beff67-7423-4d61-8ab4-f242cde38166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
